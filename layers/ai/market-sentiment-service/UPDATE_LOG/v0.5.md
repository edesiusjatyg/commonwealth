# Update Log v0.5 - PostgreSQL Migration & Smart Caching

**Date**: December 29, 2025
**Version**: 0.5.0

## Summary

Major architecture overhaul migrating from SQLite to PostgreSQL with intelligent caching strategy. Articles are now stored with 30-day TTL, while LLM analysis is performed fresh on every request (up to 10 times per token/timeframe/day).

## Major Changes

### 1. Database Migration: SQLite → PostgreSQL

**Rationale**: Better scalability, concurrent access, and production readiness.

**Changes**:
- Replaced `sqlite3` with `psycopg2-binary` and `asyncpg`
- Implemented connection pooling for better performance
- Added Docker PostgreSQL container management
- Created docker-compose.yml for easy database setup

**New Database Schema**:

```sql
-- Articles table (30-day TTL)
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    token VARCHAR(50) NOT NULL,
    timeframe VARCHAR(10) NOT NULL,
    query_date DATE NOT NULL,
    title TEXT NOT NULL,
    url TEXT NOT NULL,
    content TEXT NOT NULL,
    published_date VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(token, timeframe, query_date, url)
);

-- Query tracking table (resets daily)
CREATE TABLE query_tracking (
    id SERIAL PRIMARY KEY,
    token VARCHAR(50) NOT NULL,
    timeframe VARCHAR(10) NOT NULL,
    query_date DATE NOT NULL,
    query_count INTEGER DEFAULT 0,
    last_queried_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(token, timeframe, query_date)
);
```

### 2. Intelligent Caching Strategy

**Old Behavior** (REMOVED):
- Cached complete sentiment analysis results
- Returned cached summary without re-analyzing
- Limited fresh analysis opportunities

**New Behavior** (IMPLEMENTED):
- **Articles cached**: Full article content stored in PostgreSQL (30-day TTL)
- **LLM always runs**: Sentiment analysis and Gemini summary generated fresh every request
- **Query limits enforced**: Maximum 10 LLM queries per token/timeframe/day
- **Data reused**: Same articles used for the entire day (no redundant API calls)

**Benefits**:
- Fresh analysis reflecting current sentiment methodology
- Reduced DuckDuckGo API costs (articles cached for 30 days)
- Better LLM prompt improvements adoption (no stale cached summaries)
- Configurable query limits prevent abuse

### 3. Enhanced start.sh - Smart Installation

**Old Behavior**:
- Always removed and recreated venv
- Always reinstalled all dependencies
- No database management

**New Behavior**:

**PostgreSQL Management**:
- Checks if Docker container exists
- Validates container is running
- Verifies database schema integrity
- Creates new container only if needed
- Waits for database readiness before proceeding

**Virtual Environment**:
- Checks if venv exists and Python version matches
- Only recreates venv if Python version changed
- Preserves existing venv when possible

**Dependency Installation**:
- Tracks requirements.txt hash in `.venv/.deps_installed`
- Only reinstalls if requirements.txt changed
- Significantly faster subsequent startups

**Smart Checks**:
```bash
# Docker validation
docker ps --format '{{.Names}}' | grep container_name

# Database schema validation
docker exec container psql -tAc "SELECT COUNT(*) FROM information_schema.tables..."

# Requirements hash tracking
md5sum requirements.txt | awk '{print $1}' > .venv/.deps_installed
```

### 4. Configuration Updates

**New Environment Variables** (`.env`):
```env
# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=market_sentiment
POSTGRES_USER=sentiment_user
POSTGRES_PASSWORD=sentiment_pass

# Cache Settings
ARTICLE_CACHE_TTL_DAYS=30
MAX_QUERIES_PER_TOKEN_TIMEFRAME=10
```

**Updated `app/config.py`**:
- Added PostgreSQL connection settings
- Added cache configuration
- Bumped version to 0.2.0

### 5. API Flow Changes

**New Request Flow**:

1. **Check query limit** (new)
   - Query `query_tracking` table
   - Return 429 if limit (10) reached

2. **Check article cache**
   - Query `articles` table for today's date
   - Use cached articles if available (skip DuckDuckGo)

3. **Fetch articles if needed**
   - Call DuckDuckGo API only if no cache
   - Store full articles in PostgreSQL
   - Articles cached for 30 days

4. **Perform sentiment analysis** (always fresh)
   - VADER analysis on article content
   - Never cached

5. **Generate LLM summary** (always fresh)
   - Gemini generates new summary
   - Never cached

6. **Increment query count**
   - Update `query_tracking` table
   - Enables daily limit enforcement

**HTTP 429 Response** (new):
```json
{
  "detail": "Query limit reached for BTC (3d). Maximum 10 queries per day."
}
```

### 6. CacheManager Rewrite

**Removed Methods**:
- `get_sentiment_cache()` - No longer caching sentiment
- `set_sentiment_cache()` - No longer caching sentiment
- `get_search_cache()` - Replaced with `get_articles()`
- `set_search_cache()` - Replaced with `store_articles()`

**New Methods**:
- `get_articles()` - Retrieve full cached articles
- `store_articles()` - Store articles with content
- `check_query_limit()` - Validate daily query limit
- `increment_query_count()` - Track LLM usage
- `cleanup_old_cache()` - Remove articles older than 30 days

**Connection Management**:
- Connection pooling (1-10 connections)
- Proper connection acquisition and release
- Error handling with connection cleanup

## File Changes

### Modified Files
- `requirements.txt` - Added `psycopg2-binary`, `asyncpg`
- `app/config.py` - Added PostgreSQL settings, cache config
- `app/api.py` - New caching flow, query limit enforcement
- `services/cache_manager.py` - Complete PostgreSQL rewrite
- `start.sh` - Smart installation, Docker management

### New Files
- `.env.example` - Environment variable template
- `docker-compose.yml` - PostgreSQL container definition
- `UPDATE_LOG/v0.5.md` - This file

### Backed Up Files
- `services/cache_manager.py.bak` - Original SQLite implementation

## Breaking Changes

1. **Database Migration Required**:
   - Existing SQLite cache (cache.db) no longer used
   - Manual migration script not provided (fresh start recommended)
   - PostgreSQL must be running before starting service

2. **Environment Variables Required**:
   - Must add PostgreSQL credentials to `.env`
   - See `.env.example` for template

3. **Behavioral Change**:
   - LLM summaries no longer cached between requests
   - Each request generates fresh analysis (up to 10/day)
   - Users may notice different summaries for same token/timeframe

## Migration Guide

### For Existing Installations

1. **Backup existing cache** (optional):
   ```bash
   cp cache.db cache.db.backup
   ```

2. **Update code**:
   ```bash
   git pull origin main
   ```

3. **Add PostgreSQL config to `.env`**:
   ```bash
   cat .env.example >> .env
   # Edit .env with your preferred credentials
   ```

4. **Run start.sh** (handles everything):
   ```bash
   chmod +x start.sh
   ./start.sh
   ```

   The script will:
   - Install PostgreSQL Docker container
   - Create database and tables
   - Install Python dependencies
   - Start the service

### Manual Docker Setup (alternative)

If you prefer docker-compose:

```bash
# Start PostgreSQL
docker-compose up -d

# Verify database is ready
docker-compose ps

# Run application
source .venv/bin/activate
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## Testing

### Verify Database

```bash
# Connect to PostgreSQL
docker exec -it market-sentiment-postgres psql -U sentiment_user -d market_sentiment

# Check tables
\dt

# Query articles
SELECT token, timeframe, query_date, COUNT(*) 
FROM articles 
GROUP BY token, timeframe, query_date;

# Query tracking
SELECT * FROM query_tracking;
```

### Test Query Limits

```bash
# Make 11 requests for same token/timeframe
for i in {1..11}; do
  curl -X POST http://localhost:8000/api/v1/sentiment \
    -H "Content-Type: application/json" \
    -d '{"token": "BTC", "timeframe": "3d"}'
  echo ""
done

# 11th request should return 429 Too Many Requests
```

## Performance Impact

**Improvements**:
- ✅ Faster subsequent requests (articles cached)
- ✅ Reduced API costs (DuckDuckGo called once per day)
- ✅ More consistent article data within same day
- ✅ Better concurrent request handling (PostgreSQL)

**Considerations**:
- ⚠️ Each request runs LLM (Gemini API cost per request)
- ⚠️ Slightly higher database storage (full articles vs snippets)
- ⚠️ Docker dependency added (PostgreSQL container)

## Configuration Options

### Adjust Query Limit

In `.env`:
```env
MAX_QUERIES_PER_TOKEN_TIMEFRAME=20  # Default: 10
```

### Adjust Article TTL

In `.env`:
```env
ARTICLE_CACHE_TTL_DAYS=60  # Default: 30
```

### Database Connection Pool

In `services/cache_manager.py`:
```python
self.connection_pool = psycopg2.pool.SimpleConnectionPool(
    minconn=2,   # Default: 1
    maxconn=20,  # Default: 10
    # ...
)
```

## Known Issues

None at this time.

## Future Improvements

1. **Connection Pool Monitoring**: Add metrics for pool usage
2. **Async PostgreSQL**: Migrate to fully async asyncpg client
3. **Article Deduplication**: Detect and merge duplicate articles
4. **Configurable LLM**: Allow toggling cached vs fresh summaries
5. **Database Backup**: Automated backup strategy for PostgreSQL

## Rollback Instructions

If you need to revert to SQLite:

```bash
# Restore old cache_manager
mv services/cache_manager.py.bak services/cache_manager.py

# Revert other files
git checkout HEAD~1 requirements.txt app/config.py app/api.py start.sh

# Remove PostgreSQL container
docker stop market-sentiment-postgres
docker rm market-sentiment-postgres

# Reinstall dependencies
source .venv/bin/activate
pip install -r requirements.txt
```

---

**Contributors**: AI Assistant, parasite
**Review Status**: Ready for testing
**Deployment Status**: Development
